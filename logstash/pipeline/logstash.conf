# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}
filter {
  mutate {
    gsub => ["message",".\[8mha.+\[0m",""]
  }
  grok {
    match => ["source",".+/(?<projectName>.+)/builds/(?<buildNumber>.+)/log"]
    remove_field => ["source"]
    add_field => { "remote_ip" => "%{[@metadata][ip_address]}" }
  }

  grok {
    match => ["message","\[%{TIMESTAMP_ISO8601:temp_time}\](?<temp_message>[\s\S]+)"]
  }
  if[temp_time] and [temp_message]{

    date {
        match => ["temp_time","yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"]
        timezone => "Etc/GMT+8"
        target => "temp_time"
    }
    grok {
        match => ["temp_time","T(?<temp_time2>.+)\."]
    }
    mutate {
        update => {"message" => "[%{temp_time2}]%{temp_message}"}
        remove_field => ["temp_time","temp_time2","temp_message"]
    }
  }
  mutate {
    remove_field => ["@version","tags"]
  }
}
output {
  elasticsearch {
    hosts => ["http://192.168.200.128:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
  stdout { codec => rubydebug }
}

